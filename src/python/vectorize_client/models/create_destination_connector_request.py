# coding: utf-8

"""
    Vectorize API

    API for Vectorize services (Beta)

    The version of the OpenAPI document: 0.1.2
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import json
import pprint
from pydantic import BaseModel, ConfigDict, Field, StrictStr, ValidationError, field_validator
from typing import Any, List, Optional
from vectorize_client.models.azureaisearch import Azureaisearch
from vectorize_client.models.capella import Capella
from vectorize_client.models.datastax import Datastax
from vectorize_client.models.elastic import Elastic
from vectorize_client.models.milvus import Milvus
from vectorize_client.models.pinecone import Pinecone
from vectorize_client.models.postgresql import Postgresql
from vectorize_client.models.qdrant import Qdrant
from vectorize_client.models.singlestore import Singlestore
from vectorize_client.models.supabase import Supabase
from vectorize_client.models.turbopuffer import Turbopuffer
from vectorize_client.models.weaviate import Weaviate
from pydantic import StrictStr, Field
from typing import Union, List, Set, Optional, Dict
from typing_extensions import Literal, Self

CREATEDESTINATIONCONNECTORREQUEST_ONE_OF_SCHEMAS = ["Azureaisearch", "Capella", "Datastax", "Elastic", "Milvus", "Pinecone", "Postgresql", "Qdrant", "Singlestore", "Supabase", "Turbopuffer", "Weaviate"]

class CreateDestinationConnectorRequest(BaseModel):
    """
    CreateDestinationConnectorRequest
    """
    # data type: Capella
    oneof_schema_1_validator: Optional[Capella] = None
    # data type: Datastax
    oneof_schema_2_validator: Optional[Datastax] = None
    # data type: Elastic
    oneof_schema_3_validator: Optional[Elastic] = None
    # data type: Pinecone
    oneof_schema_4_validator: Optional[Pinecone] = None
    # data type: Singlestore
    oneof_schema_5_validator: Optional[Singlestore] = None
    # data type: Milvus
    oneof_schema_6_validator: Optional[Milvus] = None
    # data type: Postgresql
    oneof_schema_7_validator: Optional[Postgresql] = None
    # data type: Qdrant
    oneof_schema_8_validator: Optional[Qdrant] = None
    # data type: Supabase
    oneof_schema_9_validator: Optional[Supabase] = None
    # data type: Weaviate
    oneof_schema_10_validator: Optional[Weaviate] = None
    # data type: Azureaisearch
    oneof_schema_11_validator: Optional[Azureaisearch] = None
    # data type: Turbopuffer
    oneof_schema_12_validator: Optional[Turbopuffer] = None
    actual_instance: Optional[Union[Azureaisearch, Capella, Datastax, Elastic, Milvus, Pinecone, Postgresql, Qdrant, Singlestore, Supabase, Turbopuffer, Weaviate]] = None
    one_of_schemas: Set[str] = { "Azureaisearch", "Capella", "Datastax", "Elastic", "Milvus", "Pinecone", "Postgresql", "Qdrant", "Singlestore", "Supabase", "Turbopuffer", "Weaviate" }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )


    discriminator_value_class_map: Dict[str, str] = {
    }

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator('actual_instance')
    def actual_instance_must_validate_oneof(cls, v):
        instance = CreateDestinationConnectorRequest.model_construct()
        error_messages = []
        match = 0
        # validate data type: Capella
        if not isinstance(v, Capella):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Capella`")
        else:
            match += 1
        # validate data type: Datastax
        if not isinstance(v, Datastax):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Datastax`")
        else:
            match += 1
        # validate data type: Elastic
        if not isinstance(v, Elastic):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Elastic`")
        else:
            match += 1
        # validate data type: Pinecone
        if not isinstance(v, Pinecone):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Pinecone`")
        else:
            match += 1
        # validate data type: Singlestore
        if not isinstance(v, Singlestore):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Singlestore`")
        else:
            match += 1
        # validate data type: Milvus
        if not isinstance(v, Milvus):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Milvus`")
        else:
            match += 1
        # validate data type: Postgresql
        if not isinstance(v, Postgresql):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Postgresql`")
        else:
            match += 1
        # validate data type: Qdrant
        if not isinstance(v, Qdrant):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Qdrant`")
        else:
            match += 1
        # validate data type: Supabase
        if not isinstance(v, Supabase):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Supabase`")
        else:
            match += 1
        # validate data type: Weaviate
        if not isinstance(v, Weaviate):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Weaviate`")
        else:
            match += 1
        # validate data type: Azureaisearch
        if not isinstance(v, Azureaisearch):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Azureaisearch`")
        else:
            match += 1
        # validate data type: Turbopuffer
        if not isinstance(v, Turbopuffer):
            error_messages.append(f"Error! Input type `{type(v)}` is not `Turbopuffer`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when setting `actual_instance` in CreateDestinationConnectorRequest with oneOf schemas: Azureaisearch, Capella, Datastax, Elastic, Milvus, Pinecone, Postgresql, Qdrant, Singlestore, Supabase, Turbopuffer, Weaviate. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when setting `actual_instance` in CreateDestinationConnectorRequest with oneOf schemas: Azureaisearch, Capella, Datastax, Elastic, Milvus, Pinecone, Postgresql, Qdrant, Singlestore, Supabase, Turbopuffer, Weaviate. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # deserialize data into Capella
        try:
            instance.actual_instance = Capella.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Datastax
        try:
            instance.actual_instance = Datastax.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Elastic
        try:
            instance.actual_instance = Elastic.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Pinecone
        try:
            instance.actual_instance = Pinecone.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Singlestore
        try:
            instance.actual_instance = Singlestore.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Milvus
        try:
            instance.actual_instance = Milvus.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Postgresql
        try:
            instance.actual_instance = Postgresql.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Qdrant
        try:
            instance.actual_instance = Qdrant.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Supabase
        try:
            instance.actual_instance = Supabase.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Weaviate
        try:
            instance.actual_instance = Weaviate.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Azureaisearch
        try:
            instance.actual_instance = Azureaisearch.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into Turbopuffer
        try:
            instance.actual_instance = Turbopuffer.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when deserializing the JSON string into CreateDestinationConnectorRequest with oneOf schemas: Azureaisearch, Capella, Datastax, Elastic, Milvus, Pinecone, Postgresql, Qdrant, Singlestore, Supabase, Turbopuffer, Weaviate. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when deserializing the JSON string into CreateDestinationConnectorRequest with oneOf schemas: Azureaisearch, Capella, Datastax, Elastic, Milvus, Pinecone, Postgresql, Qdrant, Singlestore, Supabase, Turbopuffer, Weaviate. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(self) -> Optional[Union[Dict[str, Any], Azureaisearch, Capella, Datastax, Elastic, Milvus, Pinecone, Postgresql, Qdrant, Singlestore, Supabase, Turbopuffer, Weaviate]]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())


