/* tslint:disable */
/* eslint-disable */
/**
 * Vectorize API
 * API for Vectorize services (Beta)
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */

import { mapValues } from '../runtime';
/**
 * Configuration for Web Crawler connector
 * @export
 * @interface WEBCRAWLERConfig
 */
export interface WEBCRAWLERConfig {
    /**
     * Additional Allowed URLs or prefix(es). Add one or more allowed URLs or URL prefixes. The crawler will read URLs that match these patterns in addition to the seed URL(s).. Example: (e.g. https://docs.example.com)
     * @type {string}
     * @memberof WEBCRAWLERConfig
     */
    allowedDomainsOpt?: string;
    /**
     * Forbidden Paths. Example: Enter forbidden paths (e.g. /admin)
     * @type {string}
     * @memberof WEBCRAWLERConfig
     */
    forbiddenPaths?: string;
    /**
     * Throttle (ms). Example: Enter minimum time between requests in milliseconds
     * @type {number}
     * @memberof WEBCRAWLERConfig
     */
    minTimeBetweenRequests?: number;
    /**
     * Max Error Count. Example: Enter maximum error count
     * @type {number}
     * @memberof WEBCRAWLERConfig
     */
    maxErrorCount?: number;
    /**
     * Max URLs. Example: Enter maximum number of URLs to crawl
     * @type {number}
     * @memberof WEBCRAWLERConfig
     */
    maxUrls?: number;
    /**
     * Max Depth. Example: Enter maximum crawl depth
     * @type {number}
     * @memberof WEBCRAWLERConfig
     */
    maxDepth?: number;
    /**
     * Reindex Interval (seconds). Example: Enter reindex interval in seconds
     * @type {number}
     * @memberof WEBCRAWLERConfig
     */
    reindexIntervalSeconds?: number;
}

/**
 * Check if a given object implements the WEBCRAWLERConfig interface.
 */
export function instanceOfWEBCRAWLERConfig(value: object): value is WEBCRAWLERConfig {
    return true;
}

export function WEBCRAWLERConfigFromJSON(json: any): WEBCRAWLERConfig {
    return WEBCRAWLERConfigFromJSONTyped(json, false);
}

export function WEBCRAWLERConfigFromJSONTyped(json: any, ignoreDiscriminator: boolean): WEBCRAWLERConfig {
    if (json == null) {
        return json;
    }
    return {
        
        'allowedDomainsOpt': json['allowed-domains-opt'] == null ? undefined : json['allowed-domains-opt'],
        'forbiddenPaths': json['forbidden-paths'] == null ? undefined : json['forbidden-paths'],
        'minTimeBetweenRequests': json['min-time-between-requests'] == null ? undefined : json['min-time-between-requests'],
        'maxErrorCount': json['max-error-count'] == null ? undefined : json['max-error-count'],
        'maxUrls': json['max-urls'] == null ? undefined : json['max-urls'],
        'maxDepth': json['max-depth'] == null ? undefined : json['max-depth'],
        'reindexIntervalSeconds': json['reindex-interval-seconds'] == null ? undefined : json['reindex-interval-seconds'],
    };
}

export function WEBCRAWLERConfigToJSON(json: any): WEBCRAWLERConfig {
    return WEBCRAWLERConfigToJSONTyped(json, false);
}

export function WEBCRAWLERConfigToJSONTyped(value?: WEBCRAWLERConfig | null, ignoreDiscriminator: boolean = false): any {
    if (value == null) {
        return value;
    }

    return {
        
        'allowed-domains-opt': value['allowedDomainsOpt'],
        'forbidden-paths': value['forbiddenPaths'],
        'min-time-between-requests': value['minTimeBetweenRequests'],
        'max-error-count': value['maxErrorCount'],
        'max-urls': value['maxUrls'],
        'max-depth': value['maxDepth'],
        'reindex-interval-seconds': value['reindexIntervalSeconds'],
    };
}

